from normalizetext import *
from formatter import *
from timer import *
import random, time, math

# . , ? ! ; :
topology = [50, 50, 50, 50, 50, 2]
activation = 0.9
epsilon = 0.01

class NN:
	def __init__(self, topology):
		self.length = len(topology)
		self.lengthWeights = len(topology) - 1
		self.topology = topology
		self.weights = []
		for x in range(self.lengthWeights):
			self.weights.append([])

	def ConcatenateNeurons(self, neurons, neuronsTemp):
		for x in range(self.length):
			for y in range(self.topology[x]):
				neurons[x][y] += neuronsTemp[x][y]

	def AverageNeurons(self, neurons, length):
		for x in range(self.length):
			for y in range(self.topology[x]):
				neurons[x][y] /= length

	def RandomLayer(self, lengthLast, lengthNext):
		layer = []
		for x in range(lengthNext):
			sublayer = []
			for y in range(lengthLast):
				sublayer.append(random.random())
			layer.append(sublayer)
		return layer

	def RandomFill(self):
		for x in range(self.lengthWeights):
			self.weights[x] = self.RandomLayer(self.topology[x], self.topology[x + 1])
		#print(self.weights)

	def ZeroLayer(self, lengthLast, lengthNext):
		layer = []
		for x in range(lengthNext):
			sublayer = []
			for y in range(lengthLast):
				sublayer.append(0)
			layer.append(sublayer)
		return layer

	def ZeroFill(self):
		for x in range(self.lengthWeights):
			self.weights[x] = self.ZeroLayer(self.topology[x], self.topology[x + 1])

	def BackPropagation(self, error, neurons, epsilon):
		#print(self.weights)
		errors = []
		layer = []
		for y in range(self.topology[self.lengthWeights]):
			layer.append(error)
		errors.append(layer)

		counter = 0
		for x in range(self.lengthWeights, 0, -1):
			layer = []
			for y in range(self.topology[x - 1]):
				result = 0
				for z in range(self.topology[x]):
					result += errors[counter][z] * self.weights[x - 1][z][y]
				layer.append(result)
			errors.append(layer)
			counter += 1

		errors.reverse()
		#print(errors)
		for x in range(self.lengthWeights):
			for y in range(self.topology[x + 1]):
				for z in range(self.topology[x]):
					delta = error * neurons[x][y] * errors[x][y]
					#delta = 1 / (1 + pow(math.e, -delta))
					self.weights[x][y][z] += delta
		#print(self.weights)

	def Calculate(self, inputNeurons):
		for x in range(self.lengthWeights):
			outputNeurons = []
			for y in range(self.topology[x + 1]):
				result = 0
				for z in range(self.topology[x]):
					result += inputNeurons[y] * self.weights[x][y][z]
				result = 1 / (1 + pow(math.e, -result))
				outputNeurons.append(result)
			inputNeurons = outputNeurons
		return inputNeurons

	def CalculateData(self, data):
		text = data[0][0]
		layer = LettersIntoInputLayer(text, self.topology[0])
		layer = self.Calculate(layer)
		data[0][1] = OutputLayer2Punctuation(layer, activation)
		for x in range(1, len(data)):
			text += ' ' + data[x][0]
			layer = LettersIntoInputLayer(text, self.topology[0])
			layer = self.Calculate(layer)
			data[x][1] = OutputLayer2Punctuation(layer, activation)
		return data

	def CalculateTraining(self, inputNeurons):
		neurons = [inputNeurons]
		for x in range(self.lengthWeights):
			outputNeurons = []
			originalNeurons = []
			for y in range(self.topology[x + 1]):
				result = 0
				for z in range(self.topology[x]):
					result += inputNeurons[z] * self.weights[x][y][z]
				outputNeurons.append(result)
				result = 1 / (1 + pow(math.e, -result))
				originalNeurons.append(result)
			inputNeurons = outputNeurons
			neurons.append(originalNeurons)
		return inputNeurons, neurons

	def CalculateDataTraining(self, data):
		text = data[0][0]
		layer = LettersIntoInputLayer(text, self.topology[0])
		layer, neurons = self.CalculateTraining(layer)
		data[0][1] = OutputLayer2Punctuation(layer, activation)
		for x in range(1, len(data)):
			text += ' ' + data[x][0]
			layer = LettersIntoInputLayer(text, self.topology[0])
			layer, neuronsTemp = self.CalculateTraining(layer)
			self.ConcatenateNeurons(neurons, neuronsTemp)
			data[x][1] = OutputLayer2Punctuation(layer, activation)
		self.AverageNeurons(neurons, len(data))
		return data, neurons

def ErrorData(processed, original):
	countError = 0
	length = len(original)
	for x in range(length):
		if processed[x][1] != original[x][1]:
			countError += 1
	return countError / length

def TrainingAI(inputExample, outputExample):
	nn = NN(topology)
	nn.RandomFill()
	timer = Timer()
	counter = 1
	error = 1

	while counter != 101:
		timer.start()
		print('Generation #' + str(counter))
		data, neurons = nn.CalculateDataTraining(inputExample)
		print('Calculate data complete')#: ', data)
		#print(neurons)
		error = ErrorData(data, outputExample)
		print('Error equals', str(error))
		nn.BackPropagation(error, neurons, epsilon)
		counter += 1
		timer.stop()

folder = 'building-construction-ru'
text = ReadTXT(folder, 'data-clean.txt')
output_data = TextIntoData(text)
input_data = DeleteUsefulInformation(output_data)
TrainingAI(input_data, output_data)